library(devtools)
use_vignette(name = "MassSpectrometry",title = "Splinets Statistical Application: mass spectrometry" )
library(devtools)
use_vignette(name = "ImageClassification", title = "Image Classification with Splinets")
use_pkgdown()
pkgdown::build_site()
use_pkgdown_github_pages()
usethis::gh_token_help()
usethis::create_github_token()
gitcreds::gitcreds_set()
use_pkgdown_github_pages()
pkgdown::build_site()
devtools::build_vignettes()
pkgdown::build_site()
pkgdown::build_site()
devtools::build_vignettes()
pkgdown::build_site()
devtools::build_vignettes()
devtools::build_vignettes()
pkgdown::build_site()
usethis::use_readme_rmd()
pkgdown::build_site()
devtools::build_vignettes()
pkgdown::build_site()
n=20; k=3 #Number of knots and the order of splines
set.seed(10)
xi=sort(rbeta(n+2,2,5)); xi[1]=0; xi[n+1]=1 #Randomly distributed knots
S=matrix(rnorm((n+2)*(k+1)),ncol=(k+1)) #Random matrix of derivatives
spl=construct(xi,k,S) #A spline object with corrected matrix of the derivatives
library(Splinets)
spl=construct(xi,k,S) #A spline object with corrected matrix of the derivatives
y=rspline(spl,10) #Random spline generator
library(DDK)
# prepare the data
data_prepare <- function(f_data, t_data){
colnames(f_data) <- NULL
colnames(t_data) <- NULL
f_data <- t(f_data)
ready_data <- cbind(t_data, f_data)
ready_data <- as.matrix(ready_data)
return(ready_data)
}
# Prepare knots
Knots_prepare <- function(selected_knots, Time){
knots_normalized <- selected_knots / max(selected_knots)
knots_normalized = knots_normalized*(max(Time)- min(Time)) + min(Time)
# taking the first three decimal number
knots_normalized = as.numeric(format(round(knots_normalized,4), nsmall = 1))
return(knots_normalized)
}
library(Splinets)
data(wine)
data("Wine")
# get the data from the DKK pacakge
data("Wine")
f_data_wine <- Wine$x.learning
t_df_wine <- seq(1, dim(f_data_wine)[2])
# test data
f_data_wine_test <- Wine$x.test
t_df_wine_test <- seq(1, dim(f_data_wine_test)[2])
# remove raw 84 since it is an outlier
f_data_wine <- f_data_wine[-84,]
wine_proj = project(f_data_wine, knots) # Project wine data onto spline bases
# the knots are: 0  21  28  40  83 139 167 186 193 256
knots <- c(0, 21, 28, 40, 83, 139, 167, 186, 193, 256)
wine_proj = project(f_data_wine, knots) # Project wine data onto spline bases
# prepare the knots
Wine_DDKnots <- Knots_prepare(selected_knots = KS_wine[[1]], Time = t_df_wine)
# prepare the knots
Wine_DDKnots <- Knots_prepare(selected_knots = knots, Time = t_df_wine)
n = length(Wine_DDKnots) - 1
# prepare the data
Wine_prepared <- data_prepare(f_data = f_data_wine, t_data = t_df_wine)
wine_proj = project(f_data_wine, Wine_DDKnots) # Project wine data onto spline bases
class(f_data_wine)
dim(f_data_wine)
wine_proj = project(Wine_prepared, Wine_DDKnots) # Project wine data onto spline bases
Sigma = cov(ProjObj$coeff)  # Covariance matrix of the projection coefficients
Sigma = cov(wine_proj$coeff)  # Covariance matrix of the projection coefficients
Spect = eigen(Sigma, symmetric = T)  # eigen decomposition of the covariance matrix
EigenSp = lincomb(ProjObj$basis, t(Spect$vec))  # Create a functional eigenfunctions by linearly combining the splinets basis functions (from ProjObj$basis) with the eigenvectors (Spect$vec).
EigenSp = lincomb(wine_proj$basis, t(Spect$vec))  # Create a functional eigenfunctions by linearly combining the splinets basis functions (from ProjObj$basis) with the eigenvectors (Spect$vec).
C_mat_Wine=wine_proj$coeff %*% Spect$vec
EgenFunWine1 <- subsample(EigenSp, 1)
C_mat_Wine=wine_proj$coeff %*% Spect$vec
EgenFunWine1 <- subsample(EigenSp, 1)
{matplot(Wine_prepared[,1],Wine_prepared[,2],type='l',lty=1,xlab='',ylab='', bty="n",
col="deepskyblue4", xlim = c(-1.5,dim(f_data_wine)[2]))
lines(wine_proj$sp,sID=2-1,col='goldenrod',lty=1,lwd=1)
lines(lincomb(EgenFunWine1,C_mat_Wine[1,1,drop=F]),col='darkorange3')
abline(v = EigenSp@knots, lty = 3, lwd = 0.5)}
plot_EigenfunctionEigenValueScaled <- function(ProjCovEigObj, EigenNumber, mrgn=2, type='l', bty="n",col='deepskyblue4',
lty=1, lwd=2, xlim=NULL, ylim = NULL, xlab="", ylab = "", vknots=TRUE){
if(!is.numeric(EigenNumber)){
stop(" please insert the number of eigenfunctions as EigenMuber")
}
y = evspline(ProjCovEigObj$EigenSp, sID = 1:EigenNumber)
Arg=y[,1]
Val=y[,-1,drop=F]
# if(is.null(xlim)){
#   xlim = range(Arg)
# }
# if(is.null(ylim)){
#   ylim = range(Val)
# }
plot(Arg,Val[,1]*sqrt(ProjCovEigObj$Spect$values[1]),type=type,bty=bty,col=col,xlim=xlim,ylim=ylim,
xlab=xlab,ylab=ylab,lty=lty,lwd=lwd)
ourcol=c( 'darkorange3', 'goldenrod', 'darkorchid4',
'darkolivegreen4', 'deepskyblue', 'red4',
'slateblue','deepskyblue4')
for(i in 2:EigenNumber){
lines(Arg,Val[,i]*sqrt(ProjCovEigObj$Spect$values[i]),col=ourcol[(i-2)%%8+1],lty=lty,lwd=lwd)
}
if(vknots){
abline(v = ProjCovEigObj$EigenSp@knots, lty = 3, lwd = 0.5)
}
abline(h = 0, lwd = 0.5)
}
plot_EigenfunctionEigenValueScaled(ProjCovEigObj = WineObj, EigenNumber = 3)
source("~/.active-rstudio-document")
WineObj <- GetProjCovEig(f_ready_data = Wine_prepared, ready_knots = Wine_DDKnots)
plot_EigenfunctionEigenValueScaled(ProjCovEigObj = WineObj, EigenNumber = 3)
C_mat_Wine=WineObj$ProjObj$coeff %*% WineObj$Spect$vec
EgenFunWine1 <- subsample(WineObj$EigenSp, 1)
{matplot(Wine_prepared[,1],Wine_prepared[,2],type='l',lty=1,xlab='',ylab='', bty="n",
col="deepskyblue4", xlim = c(-1.5,dim(f_data_wine)[2]))
lines(WineObj$ProjObj$sp,sID=2-1,col='goldenrod',lty=1,lwd=1)
lines(lincomb(EgenFunWine1,C_mat_Wine[1,1,drop=F]),col='darkorange3')
abline(v = WineObj$EigenSp@knots, lty = 3, lwd = 0.5)}
devtools::build_vignettes()
pkgdown::build_site()
use_vignette(name = "IntroductiontoSplinets", title = "Introduction to Splinets")
use_vignette(name = "FunctionalPrincipalValueDecomposition", title = "Functional Principal Value Decomposition")
devtools::build_vignettes()
pkgdown::build_site()
pkgdown::build_site()
x=4, y=4
devtools::build_vignettes()
pkgdown::build_site()
library(Splinets)
# CV1=Cross(nn=nn,NumbFail = 60)
# save(CV1,file='CV1.RData')
load('CV1.RData')
class(CV1$Tr)
length(CV1$Tr)
class(CV1$Lss)
length(CV1$Lss)
nn=rep(0,K)
nn=rep(0,10)
nn
length(LT)
LT=length(CV1$Tr)
length(LT)
aaa=vector('numeric',LT)
length(aaa)
aaa
for(i in 1:LT)aaa[i]=CV1$Lss[[i]]
for(i in 1:LT)bbb[i]=sum(CV1$Tr[[i]])
bbb=aaa
for(i in 1:LT)bbb[i]=sum(CV1$Tr[[i]])
aaa
bbb
plot(bbb,aaa,type='l',xlab='The number of eigenfunctions',ylab='Accuracy',col='red',lwd=2,ylim=c(0.65,0.8))
# Load the saved data
load('MxAccu_all.RData')
load('MxAccu_all.RData')
load('MxAccu_all.RData')
# Load the saved data
load('MxAccu_all.RData')
length(CV1_list)
length(aaa_list)
CV1 <- CV1_list[[1]]
LT <- length(CV1$Tr)
#The optimal number of the eigenfunction and its classwise decomposition
jjj=1:(MC+1)
# The number of Monte Carlo iterations
MC <- length(CV1_list) - 1
MC
#The optimal number of the eigenfunction and its classwise decomposition
jjj=1:(MC+1)
j0=min(jjj[MxAccu==max(MxAccu)])
MxAccu[j0]
nn0=MxAccuArg[,j0]
sum(nn0)
# save(ClassTraj,file='ClassTraj.RData')
load('ClassTraj.RData')
xxx=sum(CV1$Tr[[1]]):sum(CV1$Tr[[LT]]) #the trajectory range by the total number of eigenfunctions
plot(xxx,aaa,ylim=c(0,1),type='l',axes='False',lwd=3, col='red',ylab='Accuracy',xlab='The total number of eigenfunctions')
axis(1)
axis(2)
# the objective function against classwise accuracy
plot(xxx,aaa,ylim=c(0,1),type='l',axes='False',lwd=3, col='red',ylab='Accuracy',xlab='The total number of eigenfunctions')
axis(1)
axis(2)
for(k in 1:K){
lines(xxx,ClassTraj[k,],type='l',col=k)
}
K=10
# the objective function against classwise accuracy
plot(xxx,aaa,ylim=c(0,1),type='l',axes='False',lwd=3, col='red',ylab='Accuracy',xlab='The total number of eigenfunctions')
axis(1)
axis(2)
for(k in 1:K){
lines(xxx,ClassTraj[k,],type='l',col=k)
}
class(xxx)
length(xxx)
dim(ClassTraj)
LT
xxx <- sapply(1:LT, function(i) sum(CV1$Tr[[i]]))
plot(xxx,aaa,ylim=c(0,1),type='l',axes='False',lwd=3, col='red',ylab='Accuracy',xlab='The total number of eigenfunctions')
axis(1)
axis(2)
# the objective function against classwise accuracy
plot(xxx,aaa,ylim=c(0,1),type='l',axes='False',lwd=3, col='red',ylab='Accuracy',xlab='The total number of eigenfunctions')
axis(1)
axis(2)
for(k in 1:K){
lines(xxx,ClassTraj[k,],type='l',col=k)
}
plot(xxx,aaa,ylim=c(0,1),type='l',axes='False',lwd=3, col='red',ylab='Accuracy',xlab='The total number of eigenfunctions')
axis(1)
axis(2)
# the objective function against classwise accuracy
plot(xxx,aaa,ylim=c(0,1),type='l',axes='False',lwd=3, col='red',ylab='Accuracy',xlab='The total number of eigenfunctions')
axis(1)
axis(2)
for(k in 1:K){
lines(xxx,ClassTraj[k,],type='l',col=k)
}
# save(ClassTraj,file='ClassTraj.RData')
load('ClassTraj.RData')
class(ClassTraj)
dim(ClassTraj)
# save(ClassTraj,file='ClassTraj.RData')
load('ClassTraj.RData')
xxx=sum(CV1$Tr[[1]]):sum(CV1$Tr[[LT]]) #the trajectory range by the total number of eigenfunctions
class(xxx)
length(xxx)
# the objective function against classwise accuracy
plot(xxx,aaa,ylim=c(0,1),type='l',axes='False',lwd=3, col='red',ylab='Accuracy',xlab='The total number of eigenfunctions')
axis(1)
axis(2)
for(k in 1:K){
lines(xxx,ClassTraj[k,],type='l',col=k)
}
lines(xxx,aaa,lwd=3, col='red')
CV1 <- CV1_list[[1]]
LT <- length(CV1$Tr)
#The optimal number of the eigenfunction and its classwise decomposition
jjj=1:(MC+1)
j0=min(jjj[MxAccu==max(MxAccu)])
MxAccu[j0]
nn0=MxAccuArg[,j0]
sum(nn0)
# # obtaining classwise trajectories
# ClassTraj=matrix(0,nrow=K,ncol=LT)
#
# for(k in 1:K){
#   DiscrData=cbind(ArgH,CrossValid[[k]])
#   for(i in 1:LT){
#     AB=Classify(DiscrData,Mean,Eg,CV1$Tr[[i]],SplData[[k]])
#     ClassTraj[k,i]=mean(AB$clss==k)
#   }
# }
# save(ClassTraj,file='ClassTraj.RData')
load('ClassTraj.RData')
xxx=sum(CV1$Tr[[1]]):sum(CV1$Tr[[LT]]) #the trajectory range by the total number of eigenfunctions
#######
# the objective function against classwise accuracy
plot(xxx,aaa,ylim=c(0,1),type='l',axes='False',lwd=3, col='red',ylab='Accuracy',xlab='The total number of eigenfunctions')
axis(1)
axis(2)
for(k in 1:K){
lines(xxx,ClassTraj[k,],type='l',col=k)
}
lines(xxx,aaa,lwd=3, col='red')
# the objective function against classwise accuracy
plot(xxx,aaa,ylim=c(0,1),type='l',axes='False',lwd=3, col='red',ylab='Accuracy',xlab='The total number of eigenfunctions')
# axis(1)
# axis(2)
for(k in 1:K){
lines(xxx,ClassTraj[k,],type='l',col=k)
}
lines(xxx,aaa,lwd=3, col='red')
plot(xxx,aaa,ylim=c(0,1),type='l',axes='False',lwd=3, col='red',ylab='Accuracy',xlab='The total number of eigenfunctions')
lines(xxx,aaa,lwd=3, col='red')
plot(xxx,aaa,ylim=c(0,1),type='l',axes='False',lwd=3, col='red',ylab='Accuracy',xlab='The total number of eigenfunctions')
axis(1)
axis(2)
lines(xxx,aaa,lwd=3, col='red')
plot(xxx,aaa,ylim=c(0,1),type='l',axes='False',lwd=3, col='red',ylab='Accuracy',xlab='The total number of eigenfunctions')
lines(xxx,aaa,lwd=3, col='red')
plot(xxx,aaa,ylim=c(0,1),type='l',axes='False',lwd=3, col='red',ylab='Accuracy',xlab='The total number of eigenfunctions')
# lines(xxx,aaa,lwd=3, col='red')
# the objective function against classwise accuracy
plot(xxx,aaa,ylim=c(0,1),type='l',axes='False',lwd=3, col='red',ylab='Accuracy',xlab='The total number of eigenfunctions')
axis(1)
axis(2)
for(k in 1:K){
lines(xxx,ClassTraj[k,],type='l',col=k)
}
# lines(xxx,aaa,lwd=3, col='red')
devtools::build_vignettes()
pkgdown::build_site()
.Last.error
devtools::build_vignettes()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_news()
pkgdown::build_news()
pkgdown::build_news()
pkgdown::build_news()
pkgdown::build_site()
devtools::build_readme()
pkgdown::build_site()
devtools::build_readme()
pkgdown::build_news()
pkgdown::build_site()
pkgdown::build_news()
pkgdown::build_site()
